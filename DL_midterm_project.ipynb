{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "R2OOtXhbCBKG"
      },
      "id": "R2OOtXhbCBKG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrrWXjYcLU3z",
        "outputId": "c9580c7e-abc4-422f-a34a-2e34481dc7c3"
      },
      "id": "YrrWXjYcLU3z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr  3 23:42:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0              44W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBECxno7LZPu",
        "outputId": "c21bcfb5-9d3f-46db-8ee6-151839e1a679"
      },
      "id": "OBECxno7LZPu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wVqPcHeGCFHA",
        "outputId": "a28d34ee-1bc4-4ffa-f572-5a0598c96c0e"
      },
      "id": "wVqPcHeGCFHA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFicZvk-PJQb",
        "outputId": "f0c91624-8080-41e6-d97b-b84b59b848ed"
      },
      "id": "UFicZvk-PJQb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13145024.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_classes = {\n",
        "    0: 'airplane',\n",
        "    1: 'automobile',\n",
        "    2: 'bird',\n",
        "    3: 'cat',\n",
        "    4: 'deer',\n",
        "    5: 'dog',\n",
        "    6: 'frog',\n",
        "    7: 'horse',\n",
        "    8: 'ship',\n",
        "    9: 'truck'\n",
        "}\n",
        "print(\"CIFAR-10 classes:\")\n",
        "for label, class_name in cifar10_classes.items():\n",
        "    print(f\"{label}: {class_name}\")"
      ],
      "metadata": {
        "id": "zukWnahYUtQD",
        "outputId": "a3b804dd-0e15-4776-ef43-6e0cd48ee812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zukWnahYUtQD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 classes:\n",
            "0: airplane\n",
            "1: automobile\n",
            "2: bird\n",
            "3: cat\n",
            "4: deer\n",
            "5: dog\n",
            "6: frog\n",
            "7: horse\n",
            "8: ship\n",
            "9: truck\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "UrlPeD5Sdcd4"
      },
      "id": "UrlPeD5Sdcd4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model 2222\n",
        "\n",
        "*   basic block [2,2,2]\n",
        "*   channels [32,64,128,256]\n",
        "*   kernal = 3\n",
        "*   stride = [1, 2, 2, 2]\n",
        "*   padding = 1\n",
        "*   downsampling\n",
        "*   batch normailzation\n",
        "*   ReLu Activation\n",
        "*   Pooling"
      ],
      "metadata": {
        "id": "nm-ttKpIdubp"
      },
      "id": "nm-ttKpIdubp"
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 32  # Reduced initial channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 32, layers[0])  # Adjusted channels\n",
        "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)  # Adjusted channels\n",
        "        self.layer3 = self._make_layer(block, 128, layers[2], stride=2)  # Adjusted channels\n",
        "        self.layer4 = self._make_layer(block, 256, layers[3], stride=2)  # Adjusted channels\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256 * block.expansion, num_classes)  # Adjusted to match reduced channels\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet18_modified(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "model = resnet18_modified().to(device)\n",
        "\n",
        "# Use the summary function\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-V9ikhBUP-e",
        "outputId": "dac4881b-75f0-48d7-e893-476bb19534a6"
      },
      "id": "k-V9ikhBUP-e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "            Conv2d-4           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
            "              ReLU-6           [-1, 32, 32, 32]               0\n",
            "            Conv2d-7           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-8           [-1, 32, 32, 32]              64\n",
            "              ReLU-9           [-1, 32, 32, 32]               0\n",
            "       BasicBlock-10           [-1, 32, 32, 32]               0\n",
            "           Conv2d-11           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-12           [-1, 32, 32, 32]              64\n",
            "             ReLU-13           [-1, 32, 32, 32]               0\n",
            "           Conv2d-14           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-15           [-1, 32, 32, 32]              64\n",
            "             ReLU-16           [-1, 32, 32, 32]               0\n",
            "       BasicBlock-17           [-1, 32, 32, 32]               0\n",
            "           Conv2d-18           [-1, 64, 16, 16]          18,432\n",
            "      BatchNorm2d-19           [-1, 64, 16, 16]             128\n",
            "             ReLU-20           [-1, 64, 16, 16]               0\n",
            "           Conv2d-21           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-22           [-1, 64, 16, 16]             128\n",
            "           Conv2d-23           [-1, 64, 16, 16]           2,048\n",
            "      BatchNorm2d-24           [-1, 64, 16, 16]             128\n",
            "             ReLU-25           [-1, 64, 16, 16]               0\n",
            "       BasicBlock-26           [-1, 64, 16, 16]               0\n",
            "           Conv2d-27           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
            "             ReLU-29           [-1, 64, 16, 16]               0\n",
            "           Conv2d-30           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 16, 16]             128\n",
            "             ReLU-32           [-1, 64, 16, 16]               0\n",
            "       BasicBlock-33           [-1, 64, 16, 16]               0\n",
            "           Conv2d-34            [-1, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-35            [-1, 128, 8, 8]             256\n",
            "             ReLU-36            [-1, 128, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "           Conv2d-39            [-1, 128, 8, 8]           8,192\n",
            "      BatchNorm2d-40            [-1, 128, 8, 8]             256\n",
            "             ReLU-41            [-1, 128, 8, 8]               0\n",
            "       BasicBlock-42            [-1, 128, 8, 8]               0\n",
            "           Conv2d-43            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-44            [-1, 128, 8, 8]             256\n",
            "             ReLU-45            [-1, 128, 8, 8]               0\n",
            "           Conv2d-46            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-47            [-1, 128, 8, 8]             256\n",
            "             ReLU-48            [-1, 128, 8, 8]               0\n",
            "       BasicBlock-49            [-1, 128, 8, 8]               0\n",
            "           Conv2d-50            [-1, 256, 4, 4]         294,912\n",
            "      BatchNorm2d-51            [-1, 256, 4, 4]             512\n",
            "             ReLU-52            [-1, 256, 4, 4]               0\n",
            "           Conv2d-53            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-54            [-1, 256, 4, 4]             512\n",
            "           Conv2d-55            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-56            [-1, 256, 4, 4]             512\n",
            "             ReLU-57            [-1, 256, 4, 4]               0\n",
            "       BasicBlock-58            [-1, 256, 4, 4]               0\n",
            "           Conv2d-59            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-60            [-1, 256, 4, 4]             512\n",
            "             ReLU-61            [-1, 256, 4, 4]               0\n",
            "           Conv2d-62            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-63            [-1, 256, 4, 4]             512\n",
            "             ReLU-64            [-1, 256, 4, 4]               0\n",
            "       BasicBlock-65            [-1, 256, 4, 4]               0\n",
            "AdaptiveAvgPool2d-66            [-1, 256, 1, 1]               0\n",
            "           Linear-67                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 2,797,610\n",
            "Trainable params: 2,797,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 7.75\n",
            "Params size (MB): 10.67\n",
            "Estimated Total Size (MB): 18.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "weqRF8s7dg96"
      },
      "id": "weqRF8s7dg96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5077a13d-c1c3-4174-bb35-92dca22210f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5077a13d-c1c3-4174-bb35-92dca22210f5",
        "outputId": "bda09f7a-3e7f-4508-bd3c-b26b3d90e841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Train Loss: 0.5816, Train Accuracy: 79.90%, Test Accuracy: 74.90%, Time: 11.88s\n",
            "Epoch 2/30, Train Loss: 0.5159, Train Accuracy: 82.13%, Test Accuracy: 82.16%, Time: 12.01s\n",
            "Epoch 3/30, Train Loss: 0.4643, Train Accuracy: 83.90%, Test Accuracy: 81.97%, Time: 12.34s\n",
            "Epoch 4/30, Train Loss: 0.4256, Train Accuracy: 85.36%, Test Accuracy: 83.94%, Time: 12.56s\n",
            "Epoch 5/30, Train Loss: 0.3916, Train Accuracy: 86.37%, Test Accuracy: 83.50%, Time: 12.00s\n",
            "Epoch 6/30, Train Loss: 0.3669, Train Accuracy: 87.14%, Test Accuracy: 83.45%, Time: 12.86s\n",
            "Epoch 7/30, Train Loss: 0.3414, Train Accuracy: 88.19%, Test Accuracy: 86.84%, Time: 12.21s\n",
            "Epoch 8/30, Train Loss: 0.3209, Train Accuracy: 88.95%, Test Accuracy: 86.10%, Time: 12.67s\n",
            "Epoch 9/30, Train Loss: 0.2967, Train Accuracy: 89.73%, Test Accuracy: 84.22%, Time: 12.72s\n",
            "Epoch 10/30, Train Loss: 0.2826, Train Accuracy: 90.23%, Test Accuracy: 87.30%, Time: 11.84s\n",
            "Epoch 11/30, Train Loss: 0.2658, Train Accuracy: 90.85%, Test Accuracy: 87.38%, Time: 11.87s\n",
            "Epoch 12/30, Train Loss: 0.2556, Train Accuracy: 91.13%, Test Accuracy: 88.04%, Time: 12.06s\n",
            "Epoch 13/30, Train Loss: 0.2356, Train Accuracy: 91.68%, Test Accuracy: 88.10%, Time: 12.84s\n",
            "Epoch 14/30, Train Loss: 0.2280, Train Accuracy: 92.00%, Test Accuracy: 87.86%, Time: 12.60s\n",
            "Epoch 15/30, Train Loss: 0.2117, Train Accuracy: 92.48%, Test Accuracy: 87.58%, Time: 12.29s\n",
            "Epoch 16/30, Train Loss: 0.2049, Train Accuracy: 92.76%, Test Accuracy: 88.71%, Time: 12.02s\n",
            "Epoch 17/30, Train Loss: 0.1934, Train Accuracy: 93.22%, Test Accuracy: 87.88%, Time: 12.40s\n",
            "Epoch 18/30, Train Loss: 0.1826, Train Accuracy: 93.67%, Test Accuracy: 86.86%, Time: 11.82s\n",
            "Epoch 19/30, Train Loss: 0.1738, Train Accuracy: 93.90%, Test Accuracy: 88.76%, Time: 12.21s\n",
            "Epoch 20/30, Train Loss: 0.1675, Train Accuracy: 94.15%, Test Accuracy: 89.52%, Time: 12.03s\n",
            "Epoch 21/30, Train Loss: 0.1635, Train Accuracy: 94.22%, Test Accuracy: 89.09%, Time: 12.19s\n",
            "Epoch 22/30, Train Loss: 0.1491, Train Accuracy: 94.74%, Test Accuracy: 89.06%, Time: 12.13s\n",
            "Epoch 23/30, Train Loss: 0.1483, Train Accuracy: 94.70%, Test Accuracy: 89.12%, Time: 12.45s\n",
            "Epoch 24/30, Train Loss: 0.1398, Train Accuracy: 95.03%, Test Accuracy: 90.39%, Time: 12.00s\n",
            "Epoch 25/30, Train Loss: 0.1328, Train Accuracy: 95.35%, Test Accuracy: 89.21%, Time: 11.99s\n",
            "Epoch 26/30, Train Loss: 0.1260, Train Accuracy: 95.52%, Test Accuracy: 89.69%, Time: 12.41s\n",
            "Epoch 27/30, Train Loss: 0.1261, Train Accuracy: 95.57%, Test Accuracy: 89.66%, Time: 11.75s\n",
            "Epoch 28/30, Train Loss: 0.1178, Train Accuracy: 95.81%, Test Accuracy: 90.23%, Time: 11.87s\n",
            "Epoch 29/30, Train Loss: 0.1139, Train Accuracy: 96.02%, Test Accuracy: 89.73%, Time: 11.78s\n",
            "Epoch 30/30, Train Loss: 0.1082, Train Accuracy: 96.09%, Test Accuracy: 89.58%, Time: 11.99s\n"
          ]
        }
      ],
      "source": [
        "#training (verbose) on CIFAR10\n",
        "import time\n",
        "\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=10):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for i, (images, labels) in enumerate(trainloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(trainloader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        model.eval()  # eval\n",
        "        with torch.no_grad():\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "              f'Train Loss: {train_loss:.4f}, '\n",
        "              f'Train Accuracy: {train_acc:.2f}%, '\n",
        "              f'Test Accuracy: {test_acc:.2f}%, '\n",
        "              f'Time: {elapsed_time:.2f}s')\n",
        "\n",
        "# Usage\n",
        "num_epochs = 30\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## predict labels"
      ],
      "metadata": {
        "id": "G8_otx39dnqP"
      },
      "id": "G8_otx39dnqP"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "def unpickle(file):\n",
        "    if not os.path.exists(file):\n",
        "        print(f\"File {file} not found.\")\n",
        "        return None\n",
        "\n",
        "    # Check the file size\n",
        "    file_size = os.path.getsize(file)\n",
        "    print(f\"File size of {file}: {file_size} bytes\")\n",
        "    if file_size == 0:\n",
        "        print(\"The file is empty.\")\n",
        "        return None\n",
        "\n",
        "    with open(file, 'rb') as fo:\n",
        "        data = pickle.load(fo, encoding='bytes')\n",
        "    return data\n",
        "\n",
        "data = unpickle('./cifar_test_nolabels.pkl')\n",
        "if data is not None:\n",
        "    print(\"File loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ITO6hGr2Iu4",
        "outputId": "97288324-67d7-4b34-f5d7-7ad3f5e55d61"
      },
      "id": "0ITO6hGr2Iu4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size of ./cifar_test_nolabels.pkl: 30800227 bytes\n",
            "File loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sanitycheck, CIFAR nolabel data is loading\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = unpickle('./cifar_test_nolabels.pkl')\n",
        "image_id = 1111 #change this to look at the image by id (goes 0 thru 9999)\n",
        "\n",
        "an_image = data[b'data'][image_id]\n",
        "an_image = an_image.reshape(3, 32, 32)\n",
        "an_image = an_image.transpose(1, 2, 0)\n",
        "\n",
        "plt.imshow(an_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WXmGFXAE5Iov",
        "outputId": "31eda5bc-2a9e-4f53-eba2-bfbe16aa59af"
      },
      "id": "WXmGFXAE5Iov",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size of ./cifar_test_nolabels.pkl: 30800227 bytes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the unlabeled data\n",
        "images = torch.tensor(data[b'data']).float()\n",
        "images = images.view(-1, 3, 32, 32)\n",
        "images = images / 255.0\n",
        "\n",
        "# Normalize images as done during training\n",
        "images = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(images)"
      ],
      "metadata": {
        "id": "--1e-pNuMj_W"
      },
      "id": "--1e-pNuMj_W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Predict\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    images = images.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Save predictions to CSV\n",
        "predictions = predicted.cpu().numpy()\n",
        "ids = np.arange(len(predictions))\n",
        "submission = pd.DataFrame({'ID': ids, 'Label': predictions})\n",
        "submission.to_csv('cifar_predictions.csv', index=False)\n",
        "print('csv prediction saved')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLK-vrbQPqJD",
        "outputId": "37e61a35-7376-4d7a-b284-63af011c273f"
      },
      "id": "PLK-vrbQPqJD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv prediction saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## other models to test"
      ],
      "metadata": {
        "id": "iGEEjS9CTBf4"
      },
      "id": "iGEEjS9CTBf4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model 333 (untested)\n",
        "\n",
        "*   [3,3,3]\n",
        "*   channels [64,128,256]\n",
        "*   kernal = 3\n",
        "*   stride = [1, 2, 2]\n",
        "*   padding = 1\n",
        "*   downsampling\n",
        "*   batch normailzation\n",
        "*   ReLu Activation\n",
        "*   Pooling\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VQxb_t7ZcA34"
      },
      "id": "VQxb_t7ZcA34"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet18_modified(num_classes=10):\n",
        "    return CustomResNet(BasicBlock, [3, 3, 3], num_classes=num_classes)\n",
        "\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ESZYQFp8XYP",
        "outputId": "c52a9f2a-3dba-4f21-85af-1624a77288bc"
      },
      "id": "1ESZYQFp8XYP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
            "              ReLU-9           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-10           [-1, 64, 32, 32]               0\n",
            "           Conv2d-11           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-12           [-1, 64, 32, 32]             128\n",
            "             ReLU-13           [-1, 64, 32, 32]               0\n",
            "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
            "             ReLU-16           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-17           [-1, 64, 32, 32]               0\n",
            "           Conv2d-18           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-19           [-1, 64, 32, 32]             128\n",
            "             ReLU-20           [-1, 64, 32, 32]               0\n",
            "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-22           [-1, 64, 32, 32]             128\n",
            "             ReLU-23           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-24           [-1, 64, 32, 32]               0\n",
            "           Conv2d-25          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-26          [-1, 128, 16, 16]             256\n",
            "             ReLU-27          [-1, 128, 16, 16]               0\n",
            "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
            "           Conv2d-30          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-31          [-1, 128, 16, 16]             256\n",
            "             ReLU-32          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-33          [-1, 128, 16, 16]               0\n",
            "           Conv2d-34          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-35          [-1, 128, 16, 16]             256\n",
            "             ReLU-36          [-1, 128, 16, 16]               0\n",
            "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
            "             ReLU-39          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-40          [-1, 128, 16, 16]               0\n",
            "           Conv2d-41          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-42          [-1, 128, 16, 16]             256\n",
            "             ReLU-43          [-1, 128, 16, 16]               0\n",
            "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
            "             ReLU-46          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-47          [-1, 128, 16, 16]               0\n",
            "           Conv2d-48            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-49            [-1, 256, 8, 8]             512\n",
            "             ReLU-50            [-1, 256, 8, 8]               0\n",
            "           Conv2d-51            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-52            [-1, 256, 8, 8]             512\n",
            "           Conv2d-53            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
            "             ReLU-55            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-56            [-1, 256, 8, 8]               0\n",
            "           Conv2d-57            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-58            [-1, 256, 8, 8]             512\n",
            "             ReLU-59            [-1, 256, 8, 8]               0\n",
            "           Conv2d-60            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-61            [-1, 256, 8, 8]             512\n",
            "             ReLU-62            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-63            [-1, 256, 8, 8]               0\n",
            "           Conv2d-64            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-65            [-1, 256, 8, 8]             512\n",
            "             ReLU-66            [-1, 256, 8, 8]               0\n",
            "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
            "             ReLU-69            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-70            [-1, 256, 8, 8]               0\n",
            "AdaptiveAvgPool2d-71            [-1, 256, 1, 1]               0\n",
            "           Linear-72                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 4,327,754\n",
            "Trainable params: 4,327,754\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 20.63\n",
            "Params size (MB): 16.51\n",
            "Estimated Total Size (MB): 37.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### add more models to test"
      ],
      "metadata": {
        "id": "NmtJK8tdhNoG"
      },
      "id": "NmtJK8tdhNoG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_R7k1JJ1t2pC"
      },
      "id": "_R7k1JJ1t2pC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}