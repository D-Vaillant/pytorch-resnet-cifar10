{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee298a7-2061-439e-aeaa-9f415c617f4e",
      "metadata": {
        "id": "7ee298a7-2061-439e-aeaa-9f415c617f4e"
      },
      "outputs": [],
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b56823f-f136-418f-9740-1b8c55655741",
      "metadata": {
        "id": "3b56823f-f136-418f-9740-1b8c55655741",
        "outputId": "5a717f10-d807-446e-ad81-ebc4372ca488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CIFAR-10 classes:\n",
            "0: airplane\n",
            "1: automobile\n",
            "2: bird\n",
            "3: cat\n",
            "4: deer\n",
            "5: dog\n",
            "6: frog\n",
            "7: horse\n",
            "8: ship\n",
            "9: truck\n"
          ]
        }
      ],
      "source": [
        "# Transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "cifar10_classes = {\n",
        "    0: 'airplane',\n",
        "    1: 'automobile',\n",
        "    2: 'bird',\n",
        "    3: 'cat',\n",
        "    4: 'deer',\n",
        "    5: 'dog',\n",
        "    6: 'frog',\n",
        "    7: 'horse',\n",
        "    8: 'ship',\n",
        "    9: 'truck'\n",
        "}\n",
        "print(\"CIFAR-10 classes:\")\n",
        "for label, class_name in cifar10_classes.items():\n",
        "    print(f\"{label}: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b908012-6cce-463d-879a-2cc308c45401",
      "metadata": {
        "id": "5b908012-6cce-463d-879a-2cc308c45401"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "\n",
        "Original source: https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    expansion = 1  # Bottleneck uses a different expansion. Not included here.\n",
        "\n",
        "    def __init__(self, input_channels, output_channels, stride=1,\n",
        "                 act_fn=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.act_fn = nn.ReLU() if act_fn is None else act_fn\n",
        "\n",
        "        self.conv1 = nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(output_channels)\n",
        "        self.conv2 = nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
        "        self.convnet = nn.Sequential(self.conv1, self.bn1, self.act_fn,\n",
        "                                     self.conv2, self.bn2)\n",
        "\n",
        "        # The logic here is actually backwards:\n",
        "        # if our stride is 1 and input_channels == output_channels, we use identity.\n",
        "        # Otherwise we use Conv2d with k = 1 and the input stride.\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or input_channels != output_channels:\n",
        "            # Adjusting if the dimensionality changes after the conv networks.\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(output_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.convnet(x) + self.shortcut(x)\n",
        "        out = self.act_fn(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResidualLayer(nn.Module):\n",
        "    def __init__(self, Block, num_blocks: int,\n",
        "                 input_channels: int, output_channels: int,\n",
        "                 stride=1, act_fn=None):\n",
        "        super(ResidualLayer, self).__init__()\n",
        "        self.act_fn = nn.ReLU() if act_fn is None else act_fn\n",
        "\n",
        "        layers = []\n",
        "        layers.append(Block(input_channels, output_channels,\n",
        "                            stride=stride, act_fn=act_fn))\n",
        "        # Subsequent blocks have stride=1.\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(Block(output_channels, output_channels,\n",
        "                                act_fn=act_fn))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    This is a ResNet. It is composed of a TRUNK and LAYERS.\n",
        "    Each LAYER is composed of several BLOCKS.\n",
        "    \"\"\"\n",
        "    resnet_act_fn = nn.ReLU()\n",
        "    block_act_fn = None\n",
        "\n",
        "    def __init__(self, block, num_blocks, num_classes=10,\n",
        "                 image_channels=3, channels=64):\n",
        "        super(ResNet, self).__init__()\n",
        "        if self.block_act_fn is None:\n",
        "            self.block_act_fn = nn.ReLU()\n",
        "\n",
        "        # Note: Different block structures aren't supported just yet.\n",
        "        # They can be hacked in by just multiplying the linear output dimension by 4.\n",
        "        assert(len(num_blocks) == 3)\n",
        "        self.channels = channels\n",
        "\n",
        "        # k = 3, p = 1\n",
        "        self.conv1 = nn.Conv2d(image_channels, self.channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.channels)\n",
        "        layer_list = []\n",
        "\n",
        "        for i, block_count in enumerate(num_blocks):\n",
        "            # The first layer is 32x32, same as the input.\n",
        "            # Then subsequent layers halve it: 16x16, 8x8, 4x4.\n",
        "            if i == 0:\n",
        "                block_stride = 1\n",
        "                output_channels = self.channels\n",
        "            else:\n",
        "                block_stride = 2\n",
        "                output_channels = 2 * self.channels\n",
        "\n",
        "            layer_list.append(ResidualLayer(\n",
        "                ResidualBlock, block_count, self.channels, output_channels,\n",
        "                stride=block_stride, act_fn=self.block_act_fn\n",
        "            ))\n",
        "            self.channels = output_channels\n",
        "\n",
        "        self.layers = nn.Sequential(*layer_list)\n",
        "        # In 3-blocks, this should be 4 * self.channels.\n",
        "        self.linear = nn.Linear(4*self.channels, num_classes)\n",
        "\n",
        "    @property\n",
        "    def trunk(self):\n",
        "        return nn.Sequential(self.conv1, self.bn1, self.resnet_act_fn)\n",
        "\n",
        "    @property\n",
        "    def parameter_count(self):\n",
        "        return sum(p.numel() for p in self.parameters())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Trunk is the first conv layer, batch, and activation function.\n",
        "        out = self.trunk(x)\n",
        "        out = self.layers(out)\n",
        "        # Hyperparameter: Pooling strategy.\n",
        "        # out = F.max_pool2d(out, 4)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ELUResNet(ResNet):\n",
        "    resnet_act_fn = nn.ELU()\n",
        "    block_act_fn = nn.ELU()\n",
        "\n",
        "class SiLUResNet(ResNet):\n",
        "    resnet_act_fn = nn.SiLU()\n",
        "    block_act_fn = nn.SiLU()\n",
        "\n",
        "\n",
        "class FatResNet(ResNet):\n",
        "    \"\"\"ResNet that uses a 5x5 kernel at the beginning.\"\"\"\n",
        "    def __init__(self, *args, image_channels=3, channels=64, **kwargs):\n",
        "        super(FatResNet, self).__init__(*args,\n",
        "                                        image_channels=image_channels,\n",
        "                                        channels=channels,\n",
        "                                        **kwargs)\n",
        "        self.conv1 = nn.Conv2d(image_channels, channels,\n",
        "                               kernel_size=5, stride=1, padding=2, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da18f0b4-fcc7-4b72-9d3b-8cb2ef649bd9",
      "metadata": {
        "id": "da18f0b4-fcc7-4b72-9d3b-8cb2ef649bd9"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"mps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3926387-3fed-4c47-89d5-c74a0674e72d",
      "metadata": {
        "id": "e3926387-3fed-4c47-89d5-c74a0674e72d"
      },
      "source": [
        "### SiLu ResNet\n",
        "\n",
        "* Residual Block [5,4,3]\n",
        "* SiLU activation function\n",
        "* channels [64,128,256]\n",
        "* kernal = 3\n",
        "* stride = [1, 2, 2]\n",
        "* padding = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a4432c-e4a2-4a11-9aa7-26bda37f3ec5",
      "metadata": {
        "id": "81a4432c-e4a2-4a11-9aa7-26bda37f3ec5",
        "outputId": "3b4e27d1-b92d-4f4a-fea9-0ee04661cb69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4778826"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net2 = SiLUResNet(ResidualBlock, [5, 4, 3], channels=64).to(device)\n",
        "\n",
        "net2.parameter_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f94549a1-d31b-403d-8675-baeb10786639",
      "metadata": {
        "id": "f94549a1-d31b-403d-8675-baeb10786639"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(net2, (3,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8deb0aa-cbc0-4624-939d-ff0e6152a1fc",
      "metadata": {
        "id": "b8deb0aa-cbc0-4624-939d-ff0e6152a1fc"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d66e52-b923-4d42-97fd-40f948e51b14",
      "metadata": {
        "id": "b0d66e52-b923-4d42-97fd-40f948e51b14"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=10):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for i, (images, labels) in enumerate(trainloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(trainloader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        model.eval()  # eval\n",
        "        with torch.no_grad():\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "              f'Train Loss: {train_loss:.4f}, '\n",
        "              f'Train Accuracy: {train_acc:.2f}%, '\n",
        "              f'Test Accuracy: {test_acc:.2f}%, '\n",
        "              f'Time: {elapsed_time:.2f}s')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef49bb85-1546-405d-acfe-1ab7b9045e45",
      "metadata": {
        "id": "ef49bb85-1546-405d-acfe-1ab7b9045e45"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net2.parameters(), lr=0.001)\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b5bb5b-62a2-4cf7-b017-96be00d13de3",
      "metadata": {
        "id": "30b5bb5b-62a2-4cf7-b017-96be00d13de3"
      },
      "outputs": [],
      "source": [
        "#train_model(net2, trainloader, testloader, criterion, optimizer, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e46ccd-7e61-455e-a7b1-8f5884bf4905",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "b9e46ccd-7e61-455e-a7b1-8f5884bf4905"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392ae590-2d5b-43ba-bc5c-d2d9bc3401ec",
      "metadata": {
        "id": "392ae590-2d5b-43ba-bc5c-d2d9bc3401ec",
        "outputId": "cf7eef60-0e49-4a49-d7a8-52b9cd1ed9fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /Users/ianadler/Desktop/Py Prog/Deep Learning/pytorch-cifar\n",
            "file does exist\n",
            "File size of ./cifar_test_nolabels.pkl: 30800227 bytes\n",
            "File loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current directory:\", current_directory)\n",
        "\n",
        "file_path = './cifar_test_nolabels.pkl'\n",
        "if os.path.exists(file_path):\n",
        "    print('file does exist')\n",
        "else:\n",
        "    print(\"File does not exist.\")\n",
        "\n",
        "\n",
        "\n",
        "def unpickle(file):\n",
        "    if not os.path.exists(file):\n",
        "        print(f\"File {file} not found.\")\n",
        "        return None\n",
        "\n",
        "    # Check the file size\n",
        "    file_size = os.path.getsize(file)\n",
        "    print(f\"File size of {file}: {file_size} bytes\")\n",
        "    if file_size == 0:\n",
        "        print(\"The file is empty.\")\n",
        "        return None\n",
        "\n",
        "    with open(file, 'rb') as fo:\n",
        "        data = pickle.load(fo, encoding='bytes')\n",
        "    return data\n",
        "\n",
        "data = unpickle('./cifar_test_nolabels.pkl')\n",
        "if data is not None:\n",
        "    print(\"File loaded successfully\")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9207e8c-d733-473a-a17d-24780a1d4cee",
      "metadata": {
        "id": "f9207e8c-d733-473a-a17d-24780a1d4cee"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the unlabeled data\n",
        "images = torch.tensor(data[b'data']).float()\n",
        "images = images.view(-1, 3, 32, 32)\n",
        "images = images / 255.0\n",
        "\n",
        "# Normalize images as done during training\n",
        "images = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae12e7a-235d-4f72-83d7-633a99facbcf",
      "metadata": {
        "id": "dae12e7a-235d-4f72-83d7-633a99facbcf"
      },
      "outputs": [],
      "source": [
        "net2cpu =  net2.to(torch.device('cpu'))\n",
        "# Predict\n",
        "net2cpu.eval()\n",
        "with torch.no_grad():\n",
        "    images = images.to(torch.device('cpu'))\n",
        "    outputs = net2cpu(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Save predictions to CSV\n",
        "predictions = predicted.cpu().numpy()\n",
        "ids = np.arange(len(predictions))\n",
        "submission = pd.DataFrame({'ID': ids, 'Label': predictions})\n",
        "submission.to_csv('predictions.csv', index=False)\n",
        "print('csv prediction saved')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}